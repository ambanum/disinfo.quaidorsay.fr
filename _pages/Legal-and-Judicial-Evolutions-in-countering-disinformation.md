---
title: Legal and Judicial Evolutions
permalink: /Legal-and-Judicial-Evolutions-in-countering-disinformation/
nav_order: 11
---

## In France: a law against intentional information manipulation

In France, a law against information manipulation and the **intentional** spread of disinformation was officially adopted on November 20, 2018, nine months after its proposal.

It focuses on massive and rapid spreads of disinformation on social media and more widely digital tools, including foreign state-owned media outlets, and was meant to be especially efficient in electoral contexts.

During said times, the law compels platforms to be more transparent by, for instance, reporting sponsored content as well as the name and invested resources of sponsors. The biggest, most used platforms are to have a legal representative in France and publish their algorithms as open data.

"Fake news" are also formally defined in order to allow for judiciary action. This definition includes massive and artificial diffusion, capacity of disturbance (of public peace or elections), and undeniability of the falsehood of the information being spread.

Outside of election times, platforms ought to cooperate, as well as build and implement open measures to fight disinformation.
The French Superior Council of the Audiovisual (CSA) has been given the authority to hinder or interrupt the broadcasting of foreign state-owned (or state-influenced) TV-services in cases where fundamental national interests are at stake.

## In the EU: The Code of Practice on Disinformation

The Code of Practice was impulsed by the **European Commission**. Signed in September 2018 and entered into force one month later, the Code was developed to achieve objectives already laid out in April of the same year regarding the **spread of disinformation online**, especially on social media platforms ahead of the European elections in May 2019.

Commitment to and implementation of the code work on a **voluntary basis** with **self-regulatory standards**.

⦁	**Signatories**

Singatories include platforms such as Facebook, Twitter, YouTube, but also Google & Mozilla. Beside representatives of online platforms and prominent social networks are advertising industry actors.

⦁	**Scope**

The application of the Code of Practices is limited for each signatory to services provided within the European Economic Area (EEA).

⦁	**Goal**

Overall, signatories must contribute to solutions to challenges raised by disinformation. As explained in the text itself, "_the purpose of this Code is to identify the actions that Signatories could put in place in order to address the challenges related to "Disinformation"_".

Among these actions are efforts towards more transparency, safeguards, scrutiny, a reduced visibility of fake information, an improvement of  the findability of trustworthy content, among others.

⦁	**Defining disinformation**

The Code offers a rather complete definition of disinformation, on which all signatories agree. Excluding "_misleading advertising, reporting errors, satire and parody, or clearly identified partisan news and commentary_", disinformation is defined as "**_verifiably false or misleading information_**" that is "_created, presented and disseminated for **economic gain** or to **intentionally deceive** the public_" ; and that "_may cause **public harm**_" and threatens "_**democratic political and policymaking processes** as well as **public goods** such as the protection of EU citizens' health, the environment or security_".

⦁	**Commitments**

The Code lists a variety of detailed measures to which signatories commit, according to their technical capabilities, the services they provide, their liability regime and "_the role they play in the creation and dissemination of the content at stake_", among other criteria.

Said measures include the **scrutiny of advertising placements** (for instance,  the deployment of policies and processes disrupting "_advertising and monetization incentives for relevant behaviours_") ; the clear and public **disclosure of political advertising and issue-based advertising** (in order to distinguish them from editorial content like news ) ; as well as the **measuring and monitoring of the effectiveness of the Code**.

Moreover, signatories commit to make efforts to **empower consumers and the research community**. Most also engage themselves to putting in place and enforce "_clear policies regarding identity and the misuse of automated bots on their services_".

To help signatories do so, best practices are detailed in the annex of the Code. However, considering the diverse nature of the signatories' operations, purposes, technologies and audiences, the Code is open to various other approaches "_accomplishing the spirit of [its] provisions_".
